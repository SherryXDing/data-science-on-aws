{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation with Scikit-Learn In This Notebook\n",
    "\n",
    "In this notebook, we convert raw text into feature embeddings.  This will allow us to perform natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/prepare_dataset_bert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Embeddings\n",
    "\n",
    "* For more details on Transformers Architecture, see [Attention Is All You Need](https://arxiv.org/abs/1706.03762)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_input_features.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **input_ids**: \n",
    "The id from the pre-trained vocabulary that represents the token. (Padding of 0 will be used if the # of tokens is less than max_seq_length)\n",
    "\n",
    "* **attention_mask**: \n",
    "Specifies which tokens should pay attention to (0 or 1). Padded input_ids will have 0 in each of these vector elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "\n",
    "if notebook_memory.total < 32 * 1024 * 1024:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True\n",
    "    print(notebook_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "def _transform_to_dataset(file, output_data, train_split_percentage, validation_split_percentage, test_split_percentage):\n",
    "    print(\"file {}\".format(file))\n",
    "\n",
    "    # Read the file\n",
    "#    df = pd.read_parquet(file)\n",
    "    df = pd.read_csv(file, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, compression=\"gzip\")\n",
    "\n",
    "    df.isna().values.any()\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)    \n",
    "\n",
    "    \n",
    "    # Split data\n",
    "    \n",
    "    print(\"Shape of dataframe before splitting {}\".format(df.shape))\n",
    "\n",
    "    print(\"train split percentage {}\".format(train_split_percentage))\n",
    "    print(\"validation split percentage {}\".format(validation_split_percentage))\n",
    "    print(\"test split percentage {}\".format(test_split_percentage))\n",
    "\n",
    "    holdout_percentage = 1.00 - train_split_percentage\n",
    "    print(\"validation holdout percentage {}\".format(holdout_percentage))\n",
    "    \n",
    "    df_train, df_holdout = train_test_split(df, test_size=holdout_percentage)\n",
    "\n",
    "    test_holdout_percentage = test_split_percentage / holdout_percentage\n",
    "    \n",
    "    print(\"test holdout percentage {}\".format(test_holdout_percentage))\n",
    "    \n",
    "    df_validation, df_test = train_test_split(\n",
    "        df_holdout, test_size=test_holdout_percentage)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_validation = df_validation.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    print(\"Shape of train dataframe {}\".format(df_train.shape))\n",
    "    print(\"Shape of validation dataframe {}\".format(df_validation.shape))\n",
    "    print(\"Shape of test dataframe {}\".format(df_test.shape))\n",
    "\n",
    "    \n",
    "    # Convert Pandas dataframes into Datasets\n",
    "    import datasets\n",
    "    from datasets import Dataset\n",
    "\n",
    "    dataset_train = Dataset.from_pandas(df_train)\n",
    "    dataset_validation = Dataset.from_pandas(df_validation)\n",
    "    dataset_test = Dataset.from_pandas(df_test)    \n",
    "\n",
    "    \n",
    "    # Tokenize\n",
    "    \n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    model_checkpoint = \"bigscience/bloom-560m\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    text_column_name = \"review_body\"\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        tokenized = tokenizer(examples[text_column_name])\n",
    "        return tokenized\n",
    "\n",
    "    import multiprocessing\n",
    "\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    print(\"num_cpus {}\".format(num_cpus))\n",
    "\n",
    "    # if using .tsv, the data will have `product_category`, but not `year`\n",
    "    # if using .parquet, the data will have also have `year`\n",
    "    tokenized_dataset_train = dataset_train.map(tokenize_function, batched=True, num_proc=num_cpus, remove_columns=[\n",
    "        'marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category',\n",
    "        'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "        'review_headline', 'review_date', text_column_name]) # 'year'\n",
    "\n",
    "    tokenized_dataset_validation = dataset_validation.map(tokenize_function, batched=True, num_proc=num_cpus, remove_columns=[\n",
    "        'marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category',\n",
    "        'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "        'review_headline', 'review_date', text_column_name]) # 'year'\n",
    "\n",
    "    tokenized_dataset_test = dataset_validation.map(tokenize_function, batched=True, num_proc=num_cpus, remove_columns=[\n",
    "        'marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category',\n",
    "        'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "        'review_headline', 'review_date', text_column_name]) # 'year'\n",
    "        \n",
    "    \n",
    "    # Group into blocks and save to S3/disk\n",
    "\n",
    "    block_size = 128\n",
    "\n",
    "    def group_texts(examples):    \n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "            # customize this part to your needs.\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "\n",
    "    lm_dataset_train = tokenized_dataset_train.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=10,\n",
    "        num_proc=num_cpus,\n",
    "    )\n",
    "\n",
    "    lm_dataset_validation = tokenized_dataset_validation.map(\n",
    "       group_texts,\n",
    "       batched=True,\n",
    "       batch_size=10,\n",
    "       num_proc=num_cpus,\n",
    "    )\n",
    "    \n",
    "    lm_dataset_test = tokenized_dataset_test.map(\n",
    "       group_texts,\n",
    "       batched=True,\n",
    "       batch_size=10,\n",
    "       num_proc=num_cpus,\n",
    "    )\n",
    "\n",
    "    print(tokenizer.decode(lm_dataset_train[1][\"input_ids\"]))\n",
    "    print(tokenizer.decode(lm_dataset_validation[1][\"input_ids\"]))\n",
    "    print(tokenizer.decode(lm_dataset_test[1][\"input_ids\"]))\n",
    "        \n",
    "    filename_without_extension = Path(Path(file).stem).stem\n",
    "\n",
    "    os.makedirs('{}/gpt3-train/'.format(output_data), exist_ok=True)\n",
    "    os.makedirs('{}/gpt3-validation/'.format(output_data), exist_ok=True)\n",
    "    os.makedirs('{}/gpt3-test/'.format(output_data), exist_ok=True)\n",
    "    \n",
    "    lm_dataset_train.to_parquet('{}/gpt3-train/{}.parquet'.format(output_data, filename_without_extension))    \n",
    "    lm_dataset_validation.to_parquet('{}/gpt3-validation/{}.parquet'.format(output_data, filename_without_extension))\n",
    "    lm_dataset_test.to_parquet('{}/gpt3-test/{}.parquet'.format(output_data, filename_without_extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import multiprocessing\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def process(args):\n",
    "\n",
    "#    input_files = glob.glob(\"{}/*.parquet\".format(args.input_data))\n",
    "    input_files = glob.glob(\"{}/*.tsv.gz\".format(args.input_data))\n",
    "    print(input_files)\n",
    "\n",
    "    print(\"Listing contents of {}\".format(args.input_data))\n",
    "    dirs_input = os.listdir(args.input_data)\n",
    "    for file in dirs_input:\n",
    "        print(file)\n",
    "\n",
    "    train_data = \"{}/gpt3-train\".format(args.output_data)\n",
    "    validation_data = \"{}/gpt3-validation\".format(args.output_data)\n",
    "    test_data = \"{}/gpt3-test\".format(args.output_data)\n",
    "\n",
    "    transform_to_dataset = functools.partial(\n",
    "        _transform_to_dataset,\n",
    "        output_data=args.output_data,\n",
    "        train_split_percentage=args.train_split_percentage, \n",
    "        validation_split_percentage=args.validation_split_percentage, \n",
    "        test_split_percentage=args.test_split_percentage,\n",
    "        # prefix=args.feature_store_offline_prefix,\n",
    "        # feature_group_name=args.feature_group_name,\n",
    "    )\n",
    "\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    print(\"num_cpus {}\".format(num_cpus))\n",
    "\n",
    "    p = multiprocessing.Pool(num_cpus)\n",
    "    p.map(transform_to_dataset, input_files)\n",
    "\n",
    "    print(\"Listing contents of {}\".format(args.output_data))\n",
    "    dirs_output = os.listdir(args.output_data)\n",
    "    for file in dirs_output:\n",
    "        print(file)\n",
    "\n",
    "    print(\"Listing contents of {}\".format(train_data))\n",
    "    dirs_output = os.listdir(train_data)\n",
    "    for file in dirs_output:\n",
    "        print(file)\n",
    "\n",
    "    print(\"Listing contents of {}\".format(validation_data))\n",
    "    dirs_output = os.listdir(validation_data)\n",
    "    for file in dirs_output:\n",
    "        print(file)\n",
    "\n",
    "    print(\"Listing contents of {}\".format(test_data))\n",
    "    dirs_output = os.listdir(test_data)\n",
    "    for file in dirs_output:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data-tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz', './data-tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', './data-tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz']\n",
      "Listing contents of ./data-tsv\n",
      "amazon_reviews_us_Gift_Card_v1_00.tsv.gz\n",
      ".ipynb_checkpoints\n",
      "amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
      "num_cpus 2\n",
      "file ./data-tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "file ./data-tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz\n",
      "Shape of dataframe before splitting (149081, 15)\n",
      "train split percentage 0.8\n",
      "validation split percentage 0.1\n",
      "test split percentage 0.1\n",
      "validation holdout percentage 0.19999999999999996\n",
      "test holdout percentage 0.5000000000000001\n",
      "Shape of train dataframe (119264, 15)\n",
      "Shape of validation dataframe (14908, 15)\n",
      "Shape of test dataframe (14909, 15)\n",
      "Shape of dataframe before splitting (102084, 15)\n",
      "train split percentage 0.8\n",
      "validation split percentage 0.1\n",
      "test split percentage 0.1\n",
      "validation holdout percentage 0.19999999999999996\n",
      "test holdout percentage 0.5000000000000001\n",
      "Shape of train dataframe (81667, 15)\n",
      "Shape of validation dataframe (10208, 15)\n",
      "Shape of test dataframe (10209, 15)\n",
      "num_cpus 2\n",
      "num_cpus 2\n",
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b949df8e3a4c4b8f79e51a471836d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/60 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cf21ea64ee4966bed460df2d797d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/41 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6204a714264d56b01db5ec9808fdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/60 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8ab4fa59124c189651822c14e43a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/41 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2594abab5d724eb7b647acda51f84f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f842d353faf41f7827a192a587c3ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1734fe7748049bc923677641eaf9690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3fa2e0444c463ab7cd6dc755281081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb2eae395444ad9a178e8d62b335de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e605b9212a9949db941180e316a58056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef63d4eb95cd497d9dc6c2e3bee00303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/5964 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d464b740bfe45a4879a56ead52149b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/5964 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d280f8241e4c24bfc052fe1f7f49e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3eccca32db4f9b978f653db2bf74e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0764bee48b498a86d4f1e67398f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/4084 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b934bdf156a4667b1c580afe503874c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/4084 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1b2412e1084322965c2ca37d6a0227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/746 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050cf51981c14fd48bb21409b363daa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/746 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946420fa44164049adf8afc46716c126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/746 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ad4162141a484e95c6e045ba568279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/746 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a084bc8738436daf0960fe685bf1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/511 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62bf9f43d144a229197deda8eb9a098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/511 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14905a88d1554703884d228f122e0d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/511 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a3cbf0355643ab8c43b29682a48acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/511 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was perfectGot a gift card for my sister at Christmas!  Perfect for the person who has everything, right?  She likes to read and if she doesn't want a book, she can purchase a large variety of other things-dvd's, fish line, electronics, etc.Excellent...I got this for my husband for Christmas so he could purchase some movies or music for himself. It was easy to purchase and print out last-minute on Christmas morning. It turned out he did the same for me, haha.Fast and perfect!!Good gift for my distant family, they enjoy to purchase thousands gifts in Amazon, the only bad is\n",
      "love e-giftcards.. easy to send and received immediately.  I use them a lot.. for myself and others... good to know I can choose a gift quickly and have them received immediately.excellent!ThanksNext day delivery... what more can you ask for!  The gift card was purchased as a Christmas gift for someone who has a Kindle Fire HD.  It arrived as promised and the gift wrapped box was perfect!With my Son and his wife and children living in Vietnam moving to China it made giving them a gift so much easier and on time.  Thanks so much!I am trying to contact amazon, I sent a gift card\n",
      "love e-giftcards.. easy to send and received immediately.  I use them a lot.. for myself and others... good to know I can choose a gift quickly and have them received immediately.excellent!ThanksNext day delivery... what more can you ask for!  The gift card was purchased as a Christmas gift for someone who has a Kindle Fire HD.  It arrived as promised and the gift wrapped box was perfect!With my Son and his wife and children living in Vietnam moving to China it made giving them a gift so much easier and on time.  Thanks so much!I am trying to contact amazon, I sent a gift card\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70418a6a7c64ab481f5f4a7e7204a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823ce2e7992c49179f769f3d9222dad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc89f2df6f64e3ab1af61d65d4d0cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./data-tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
      " sort of digital Ex-lax to get his thing moving? Also I have to keep shutting it down and restarting it because like the Greek Civil Service it decides to take a coffee break and go away whenever it feels like it. The upside is that I am really enjoying watching this big spider spin its beautiful web across my keyboard because the time between my keystrokes can be measured in mosquito outbreaks. The positive aspects of this program? I hear the new features are great...I can't wait to use them...maybe one day before LR5 comes out. Until then I hope that I have many new knit sweaters\n",
      " to go to a spreadsheet I found on line for free.  Spreadsheet works fine and is user friendly. Deleted Quicken from my computer.TurboTax did the job this year as it has in the past.<br />I was easily able to import last year's data as well as download my tax documents from my payroll company and my brokerage.<br />This helped save me a lot of time and error prone typing.<br /><br />As to the people complaining about having to buy TurboTax &#34;Premier&#34; instead of &#34;Deluxe&#34; to get the schedule D features, all I can say is\n",
      " to go to a spreadsheet I found on line for free.  Spreadsheet works fine and is user friendly. Deleted Quicken from my computer.TurboTax did the job this year as it has in the past.<br />I was easily able to import last year's data as well as download my tax documents from my payroll company and my brokerage.<br />This helped save me a lot of time and error prone typing.<br /><br />As to the people complaining about having to buy TurboTax &#34;Premier&#34; instead of &#34;Deluxe&#34; to get the schedule D features, all I can say is\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3b02db2f48415d8cb481b4cfc13b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe before splitting (145427, 15)\n",
      "train split percentage 0.8\n",
      "validation split percentage 0.1\n",
      "test split percentage 0.1\n",
      "validation holdout percentage 0.19999999999999996\n",
      "test holdout percentage 0.5000000000000001\n",
      "Shape of train dataframe (116341, 15)\n",
      "Shape of validation dataframe (14542, 15)\n",
      "Shape of test dataframe (14544, 15)\n",
      "num_cpus 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3690cd4b879466e91dbb04fca78c575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc4cd4698d44f90bae8fb90b27f0bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d06658cff94fb0aaecc313f1fbde11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162fb20b5124489f9b0727f3d4a51133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/59 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed0ee4d8d3548bba3ad6ee258aaa18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8df519e9bf94ab8a8b5fdc9b7865163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b73d3b8509048cfada75947b99dcd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce374d9d3b944a9a11cc4c26545d1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2afa2c1a2fb4755a061d841b4f1f136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/5818 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d31dd4f2304521a3c3972d0bf41100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/5817 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cef039095d41dc9dfe5cb36a36cd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/728 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e551634f954453bb8328274f4cfdced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/728 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d721974dc00c40b0bc4b4214c3a6b314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/728 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a35ae1d5cb64bcc994eb7297827bd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/728 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " easy and convenient.UPDATE: The game is great. Simcity probably had one of the worst game launches of all time, but they have bounded back and have made me a very happy customer. They are constantly releasing updates, fixes, and new content to make it enjoyable. And to make up for the terrible launch, us \\\\\"early adopters\\\\\" got a free game (an older one, but still nice) and access to an exclusive \\\\\"theme park\\\\\" in-game. If you've watched any videos about the game, then that is truly the experience you will have with this game now. The only issue is the\n",
      " up I could sleep.I am a huge fan of games such as Fable, Elder Scrolls, Diablo, Mass Effect, Dungeon Siege, Fallout, etc. This lesser-known game deserves a spot with the rest of those games.<br />You can find all kinds of reviews online for this game, so I won't go into too much detail - I just want to give this game 5 stars and tell you that if you enjoy rpg's, this is a must-have.<br /><br />The game has been criticized for being 'too generic' and borrowing too much from other games. But I think this\n",
      " up I could sleep.I am a huge fan of games such as Fable, Elder Scrolls, Diablo, Mass Effect, Dungeon Siege, Fallout, etc. This lesser-known game deserves a spot with the rest of those games.<br />You can find all kinds of reviews online for this game, so I won't go into too much detail - I just want to give this game 5 stars and tell you that if you enjoy rpg's, this is a must-have.<br /><br />The game has been criticized for being 'too generic' and borrowing too much from other games. But I think this\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd75891e87254fc5ac0662796de1abb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/69 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b3229fa5354f3dbaf239b36afd0e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1f5b041a4046dc8e619f91182f6fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing contents of ./data-gpt3\n",
      ".ipynb_checkpoints\n",
      "gpt3-validation\n",
      "gpt3-train\n",
      "gpt3-test\n",
      "Listing contents of ./data-gpt3/gpt3-train\n",
      "amazon_reviews_us_Gift_Card_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Video_Games_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Software_v1_00.parquet\n",
      "Listing contents of ./data-gpt3/gpt3-validation\n",
      "amazon_reviews_us_Gift_Card_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Video_Games_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Software_v1_00.parquet\n",
      "Listing contents of ./data-gpt3/gpt3-test\n",
      "amazon_reviews_us_Gift_Card_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Video_Games_v1_00.parquet\n",
      "amazon_reviews_us_Digital_Software_v1_00.parquet\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    input_data: str\n",
    "    output_data: str\n",
    "    train_split_percentage: float\n",
    "    validation_split_percentage: float\n",
    "    test_split_percentage: float\n",
    "\n",
    "args = Args()    \n",
    "    \n",
    "#args.input_data = '../../data-science-on-aws.gpt3/00_quickstart/data-parquet/Digital_Software'\n",
    "args.input_data = './data-tsv'\n",
    "args.output_data = './data-gpt3'\n",
    "args.train_split_percentage = .80\n",
    "args.validation_split_percentage = .10\n",
    "args.test_split_percentage = .10\n",
    "\n",
    "process(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9xVAa3s3l-2"
   },
   "source": [
    "Then we apply it to all the splits in our `datasets` object, using `batched=True` and 4 processes to speed up the preprocessing. We won't need the `text` column afterward, so we discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-778b367b1c7dc7dd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /root/.cache/huggingface/datasets/parquet/default-778b367b1c7dc7dd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0af991336b4956a999a9da651d143d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8241b9562cf64432abf67c050efd8f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/default-778b367b1c7dc7dd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0ddde35a3328bef9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /root/.cache/huggingface/datasets/parquet/default-0ddde35a3328bef9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0b6a3798f542ea9076836495ca0a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15d4b60d3144470b5c204c3968ebb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/default-0ddde35a3328bef9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-be74b8e8585efa07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /root/.cache/huggingface/datasets/parquet/default-be74b8e8585efa07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a946f9116694496d9f37d17fc15b9b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4629a9c6b6b64407ba456cecf1136ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/default-be74b8e8585efa07/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "reloaded_dataset_train = Dataset.from_parquet('./data-gpt3/gpt3-train/*.parquet')\n",
    "reloaded_dataset_validation = Dataset.from_parquet('./data-gpt3/gpt3-validation/*.parquet')\n",
    "reloaded_dataset_test = Dataset.from_parquet('./data-gpt3/gpt3-test/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 138117\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 17171\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 17171\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
